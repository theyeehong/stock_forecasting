{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fdab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from datetime import datetime, timedelta\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.palettes import Category10\n",
    "from bokeh.models import HoverTool\n",
    "from ta.trend import SMAIndicator, EMAIndicator, MACD\n",
    "from ta.momentum import RSIIndicator\n",
    "from ta.volatility import BollingerBands\n",
    "from ta.volume import OnBalanceVolumeIndicator\n",
    "import time\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6304d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = os.path.join(\"..\", \"data\", \"stock_data.db\")\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    device_name = gpus[0].name\n",
    "    print(f\"Using GPU: {device_name}\")\n",
    "else:\n",
    "    device_name = \"/CPU:0\"\n",
    "    print(\"GPU not found, using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e04f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = {\n",
    "    'MBSB': '1171.KL'\n",
    "}\n",
    "\n",
    "num_tickers = len(tickers)\n",
    "sequence_length = 90\n",
    "output_length = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202126d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stock_data = {}\n",
    "for name, ticker in tickers.items():\n",
    "    data = yf.download(ticker, period=\"5y\", interval=\"1d\")\n",
    "    if not data.empty:\n",
    "        data.to_sql(name, conn, if_exists='replace', index=True)\n",
    "        all_stock_data[name] = data\n",
    "        print(f\"{name}: {len(data)} days - saved to database\")\n",
    "    else:\n",
    "        try:\n",
    "            data = pd.read_sql(f\"SELECT * FROM {name}\", conn, index_col='Date', parse_dates=['Date'])\n",
    "            all_stock_data[name] = data\n",
    "            print(f\"{name}: No new data, loaded from database ({len(data)} days)\")\n",
    "        except:\n",
    "            print(f\"{name}: No data found and no database backup available\")\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255f913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "\n",
    "p = figure(title=\"MBSB - Historical Closing Prices\",\n",
    "           x_axis_type='datetime',\n",
    "           width=1300,\n",
    "           height=600,\n",
    "           tools=\"pan,wheel_zoom,box_zoom,reset,save\")\n",
    "\n",
    "colors = Category10[10]\n",
    "\n",
    "for i, (name, data) in enumerate(all_stock_data.items()):\n",
    "    color = colors[i % len(colors)]\n",
    "    p.line(data.index, data['Close'], legend_label=name, line_width=2, color=color)\n",
    "\n",
    "hover = HoverTool(tooltips=[(\"Date\", \"@x{%F}\"), (\"Price\", \"@y\")], formatters={\"@x\": \"datetime\"})\n",
    "p.add_tools(hover)\n",
    "\n",
    "p.legend.click_policy=\"hide\"\n",
    "p.legend.location=\"top_left\"\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a3f6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_features(data):\n",
    "    df = data.copy()\n",
    "    df['SMA_20'] = SMAIndicator(df['Close'], window=20).sma_indicator()\n",
    "    df['EMA_50'] = EMAIndicator(df['Close'], window=50).ema_indicator()\n",
    "    df['MACD'] = MACD(df['Close']).macd()\n",
    "    df['RSI_14'] = RSIIndicator(df['Close'], window=14).rsi()\n",
    "    df['Momentum_10'] = df['Close'] / df['Close'].shift(10) - 1\n",
    "    bb = BollingerBands(df['Close'], window=20, window_dev=2)\n",
    "    df['BB_upper'] = bb.bollinger_hband()\n",
    "    df['BB_lower'] = bb.bollinger_lband()\n",
    "    df['ATR_14'] = (df['High'] - df['Low']).rolling(14).mean()\n",
    "    obv = OnBalanceVolumeIndicator(df['Close'], df['Volume'])\n",
    "    df['OBV'] = obv.on_balance_volume()\n",
    "    return df\n",
    "\n",
    "combined_data = []\n",
    "for name, data in all_stock_data.items():\n",
    "    df = pd.DataFrame({\n",
    "        'Date': data.index,\n",
    "        'Open': data['Open'].values.flatten(),\n",
    "        'High': data['High'].values.flatten(),\n",
    "        'Low': data['Low'].values.flatten(),\n",
    "        'Close': data['Close'].values.flatten(),\n",
    "        'Volume': data['Volume'].values.flatten(),\n",
    "        'Stock': name\n",
    "    })\n",
    "    df = calculate_features(df)\n",
    "    combined_data.append(df)\n",
    "\n",
    "stock_order = list(all_stock_data.keys())\n",
    "combined_df = pd.concat(combined_data, ignore_index=True)\n",
    "combined_df['Stock'] = pd.Categorical(combined_df['Stock'], categories=stock_order, ordered=True)\n",
    "combined_df = combined_df.sort_values(['Date', 'Stock']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b32c478",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['Open', 'High', 'Low', 'Close', 'Volume', 'SMA_20', 'EMA_50', \n",
    "                   'MACD', 'RSI_14', 'Momentum_10', 'BB_upper', 'BB_lower', 'ATR_14', 'OBV']\n",
    "n_features = len(feature_columns)\n",
    "combined_df_clean = combined_df[feature_columns].dropna()\n",
    "\n",
    "scaler_features = MinMaxScaler()\n",
    "scaler_target = MinMaxScaler()\n",
    "all_features = combined_df_clean[feature_columns].values\n",
    "all_targets = combined_df_clean[['Close']].values\n",
    "\n",
    "scaler_features.fit(all_features)\n",
    "scaler_target.fit(all_targets)\n",
    "scaled_features = scaler_features.transform(all_features)\n",
    "scaled_targets = scaler_target.transform(all_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa692218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(features, targets, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(seq_length, len(features), num_tickers):\n",
    "        X.append(features[i-seq_length:i])\n",
    "        y.append(targets[i])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = create_sequences(scaled_features, scaled_targets, sequence_length)\n",
    "print(f\"X shape: {X.shape} (samples, time_steps, features)\")\n",
    "print(f\"y shape: {y.shape} (samples, 1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ae0a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.80\n",
    "split_index = int(len(X) * split_ratio)\n",
    "\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Testing samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50baa8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tf.keras.models\n",
    "layers = tf.keras.layers\n",
    "callbacks = tf.keras.callbacks\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.LSTM(units=100, return_sequences=True, input_shape=(sequence_length, n_features)),\n",
    "    layers.Dropout(0.3),\n",
    "    \n",
    "    layers.LSTM(units=100, return_sequences=True),\n",
    "    layers.Dropout(0.3),\n",
    "    \n",
    "    layers.LSTM(units=80, return_sequences=True),\n",
    "    layers.Dropout(0.2),\n",
    "    \n",
    "    layers.LSTM(units=80, return_sequences=False),\n",
    "    layers.Dropout(0.2),\n",
    "    \n",
    "    layers.Dense(units=50, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    \n",
    "    layers.Dense(units=output_length)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "print(\"Model built successfully!\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c91f6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Phase1: Training model without early stopping\")\n",
    "start_time = time.time()\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(\"Training complete\")\n",
    "print(f\"Total training time: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16456bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss During Training')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8b57de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Phase2: Training model with early stopping\")\n",
    "start_time = time.time()\n",
    "\n",
    "early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history2 = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(\"Training complete!\")\n",
    "print(f\"Total training time: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba68132",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(history2.history['loss'], label='Training Loss')\n",
    "plt.plot(history2.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss During Training')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed64dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(\"models\", \"mbsb_model.h5\")\n",
    "model.save(model_path)\n",
    "print(\"Model saved\")\n",
    "\n",
    "scaler_features_path = os.path.join(\"scalers\", \"mbsb_scaler_features.pkl\")\n",
    "scaler_target_path = os.path.join(\"scalers\", \"mbsb_scaler_target.pkl\")\n",
    "joblib.dump(scaler_features, scaler_features_path)\n",
    "joblib.dump(scaler_target, scaler_target_path)\n",
    "print(\"Scaler saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6255571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Making predictions on test set...\")\n",
    "y_pred_scaled = model.predict(X_test)\n",
    "y_pred = scaler_target.inverse_transform(y_pred_scaled)\n",
    "y_actual = scaler_target.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af876fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_actual, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_actual, y_pred)\n",
    "r2 = r2_score(y_actual, y_pred)\n",
    "mape = np.mean(np.abs((y_actual - y_pred) / y_actual)) * 100\n",
    "\n",
    "print(\"\\n=== Model Performance Metrics ===\")\n",
    "print(f\"RMSE: RM {rmse:.4f}\")\n",
    "print(f\"MAE: RM {mae:.4f}\")\n",
    "print(f\"RÂ² Score: {r2:.4f}\")\n",
    "print(f\"MAPE: {mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3e1d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(y_actual, label='Actual Price', color='blue', linewidth=2)\n",
    "plt.plot(y_pred, label='Predicted Price', color='red', linewidth=2, alpha=0.7)\n",
    "plt.title('MBSB: Actual vs Predicted Stock Prices (Test Set)')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Price (RM)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2585572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_future(model, last_seq, scaler_features, scaler_target, n_days=30):\n",
    "    \"\"\"Predict multiple days into the future\"\"\"\n",
    "    predictions = []\n",
    "    current_seq = last_seq.copy()\n",
    "    \n",
    "    for _ in range(n_days):\n",
    "        # Predict next day\n",
    "        pred_scaled = model.predict(current_seq, verbose=0)\n",
    "        pred_price = scaler_target.inverse_transform(pred_scaled)[0][0]\n",
    "        predictions.append(pred_price)\n",
    "        \n",
    "        # Update sequence: remove first day, add prediction\n",
    "        # We need to create a full feature vector for the prediction\n",
    "        # For simplicity, we'll duplicate the last feature set and update Close\n",
    "        new_features = current_seq[0, -1, :].copy()\n",
    "        \n",
    "        # Update the Close price in the feature vector\n",
    "        close_idx = feature_columns.index('Close')\n",
    "        new_features[close_idx] = pred_scaled[0][0]  # scaled value\n",
    "        \n",
    "        # Reshape and append\n",
    "        new_features = new_features.reshape(1, 1, n_features)\n",
    "        current_seq = np.concatenate([current_seq[:, 1:, :], new_features], axis=1)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21a966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_days = 7\n",
    "last_seq = scaled_features[-sequence_length:].reshape(1, sequence_length, n_features)\n",
    "future_prices = predict_future(model, last_seq, scaler_features, scaler_target, forecast_days)\n",
    "last_date = combined_df_clean['Date'].iloc[-1] if 'Date' in combined_df_clean.columns else combined_df['Date'].iloc[-1]\n",
    "future_dates = pd.date_range(start=last_date + timedelta(days=1), periods=forecast_days, freq='D')\n",
    "historical_data = combined_df_clean['Close'].tail(90)\n",
    "historical_dates = combined_df['Date'].tail(90) if 'Date' in combined_df.columns else range(len(historical_data))\n",
    "\n",
    "plt.plot(historical_dates, historical_data.values, \n",
    "         label='Historical Price', color='blue', linewidth=2)\n",
    "plt.plot(future_dates, future_prices, \n",
    "         label=f'{forecast_days}-Day Forecast', color='red', \n",
    "         linewidth=2, linestyle='--', marker='o', markersize=3)\n",
    "\n",
    "plt.axvline(x=last_date, color='green', linestyle=':', linewidth=2, label='Today')\n",
    "plt.title(f'MBSB: {forecast_days}-Day Price Forecast')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price (RM)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae459a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_prices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
