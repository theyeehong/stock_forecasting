{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fdab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.palettes import Category10\n",
    "from bokeh.models import HoverTool\n",
    "from ta.trend import SMAIndicator, EMAIndicator, MACD\n",
    "from ta.momentum import RSIIndicator\n",
    "from ta.volatility import BollingerBands, AverageTrueRange\n",
    "from ta.volume import OnBalanceVolumeIndicator\n",
    "import time\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e37814d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "# Optional: force garbage collection\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6304d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: /physical_device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "db_path = os.path.join(\"data\", \"stock_data.db\")\n",
    "os.makedirs(os.path.dirname(db_path), exist_ok=True)\n",
    "\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    pass\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f\"Using GPU: {gpus[0].name}\" if gpus else \"GPU not found, using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2e04f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = {\n",
    "    'CIMB': '1023.KL',\n",
    "    'MAYBANK': '1155.KL',\n",
    "    'HLB': '5819.KL',\n",
    "    'AMMB': '1015.KL',\n",
    "    'BANKISLAM': '5258.KL',\n",
    "    'AFFIN': '5185.KL',\n",
    "    'PBBank': '1295.KL',\n",
    "    'RHB': '1066.KL',\n",
    "    'ALLIANCE': '2488.KL'\n",
    "}\n",
    "\n",
    "sequence_length = 90\n",
    "output_length = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "202126d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/j8blh6ss0q14j_zchnm79lb00000gn/T/ipykernel_15491/2441710567.py:3: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, period=\"5y\", interval=\"1d\")\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/j1/j8blh6ss0q14j_zchnm79lb00000gn/T/ipykernel_15491/2441710567.py:3: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, period=\"5y\", interval=\"1d\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIMB: 1227 days - saved to database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/j1/j8blh6ss0q14j_zchnm79lb00000gn/T/ipykernel_15491/2441710567.py:3: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, period=\"5y\", interval=\"1d\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAYBANK: 1227 days - saved to database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/j1/j8blh6ss0q14j_zchnm79lb00000gn/T/ipykernel_15491/2441710567.py:3: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, period=\"5y\", interval=\"1d\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HLB: 1227 days - saved to database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/j1/j8blh6ss0q14j_zchnm79lb00000gn/T/ipykernel_15491/2441710567.py:3: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, period=\"5y\", interval=\"1d\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMMB: 1227 days - saved to database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/j1/j8blh6ss0q14j_zchnm79lb00000gn/T/ipykernel_15491/2441710567.py:3: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, period=\"5y\", interval=\"1d\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BANKISLAM: 1227 days - saved to database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/j1/j8blh6ss0q14j_zchnm79lb00000gn/T/ipykernel_15491/2441710567.py:3: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, period=\"5y\", interval=\"1d\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFFIN: 1227 days - saved to database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/j1/j8blh6ss0q14j_zchnm79lb00000gn/T/ipykernel_15491/2441710567.py:3: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, period=\"5y\", interval=\"1d\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PBBank: 1227 days - saved to database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/j1/j8blh6ss0q14j_zchnm79lb00000gn/T/ipykernel_15491/2441710567.py:3: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, period=\"5y\", interval=\"1d\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RHB: 1227 days - saved to database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALLIANCE: 1227 days - saved to database\n",
      "DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_stock_data = {}\n",
    "for name, ticker in tickers.items():\n",
    "    data = yf.download(ticker, period=\"5y\", interval=\"1d\")\n",
    "    if not data.empty:\n",
    "        data.to_sql(name, conn, if_exists='replace', index=True)\n",
    "        all_stock_data[name] = data\n",
    "        print(f\"{name}: {len(data)} days - saved to database\")\n",
    "    else:\n",
    "        try:\n",
    "            data = pd.read_sql(f\"SELECT * FROM {name}\", conn, index_col='Date', parse_dates=['Date'])\n",
    "            all_stock_data[name] = data\n",
    "            print(f\"{name}: No new data, loaded from database ({len(data)} days)\")\n",
    "        except:\n",
    "            print(f\"{name}: No data found and no database backup available\")\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255f913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "\n",
    "p = figure(title=\"Malaysian Bank Stocks - Historical Closing Prices\",\n",
    "           x_axis_type='datetime',\n",
    "           width=1300,\n",
    "           height=600,\n",
    "           tools=\"pan,wheel_zoom,box_zoom,reset,save\")\n",
    "\n",
    "colors = Category10[10]\n",
    "\n",
    "for i, (name, data) in enumerate(all_stock_data.items()):\n",
    "    color = colors[i % len(colors)]\n",
    "    p.line(data.index, data['Close'], legend_label=name, line_width=2, color=color)\n",
    "\n",
    "hover = HoverTool(tooltips=[(\"Date\", \"@x{%F}\"), (\"Price\", \"@y\")], formatters={\"@x\": \"datetime\"})\n",
    "p.add_tools(hover)\n",
    "\n",
    "p.legend.click_policy=\"hide\"\n",
    "p.legend.location=\"top_left\"\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a3f6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_features(data):\n",
    "    df = data.copy()\n",
    "    df['SMA_20'] = SMAIndicator(df['Close'], window=20).sma_indicator()\n",
    "    df['EMA_50'] = EMAIndicator(df['Close'], window=50).ema_indicator()\n",
    "    df['MACD'] = MACD(df['Close']).macd()\n",
    "    df['RSI_14'] = RSIIndicator(df['Close'], window=14).rsi()\n",
    "    df['Momentum_10'] = df['Close'] / df['Close'].shift(10) - 1\n",
    "    bb = BollingerBands(df['Close'], window=20, window_dev=2)\n",
    "    df['BB_upper'] = bb.bollinger_hband()\n",
    "    df['BB_lower'] = bb.bollinger_lband()\n",
    "    df['ATR_14'] = (df['High'] - df['Low']).rolling(14).mean()\n",
    "    obv = OnBalanceVolumeIndicator(df['Close'], df['Volume'])\n",
    "    df['OBV'] = obv.on_balance_volume()\n",
    "    return df\n",
    "\n",
    "combined_data = []\n",
    "for name, data in all_stock_data.items():\n",
    "    df = pd.DataFrame({\n",
    "        'Date': data.index,\n",
    "        'Open': data['Open'].values.flatten(),\n",
    "        'High': data['High'].values.flatten(),\n",
    "        'Low': data['Low'].values.flatten(),\n",
    "        'Close': data['Close'].values.flatten(),\n",
    "        'Volume': data['Volume'].values.flatten(),\n",
    "        'Stock': name\n",
    "    })\n",
    "    df = calculate_features(df)\n",
    "    combined_data.append(df)\n",
    "    \n",
    "feature_columns = ['Open', 'High', 'Low', 'Close', 'Volume', 'SMA_20', 'EMA_50', \n",
    "                   'MACD', 'RSI_14', 'Momentum_10', 'BB_upper', 'BB_lower', 'ATR_14', 'OBV']\n",
    "n_features = len(feature_columns)\n",
    "\n",
    "stock_order = list(all_stock_data.keys())\n",
    "combined_df = pd.concat(combined_data, ignore_index=True)\n",
    "combined_df['Stock'] = pd.Categorical(combined_df['Stock'], categories=stock_order, ordered=True)\n",
    "combined_df = combined_df.sort_values(['Date', 'Stock']).reset_index(drop=True)\n",
    "combined_df_clean = combined_df[feature_columns].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175a605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = combined_df[feature_columns].corr()\n",
    "print(\"Feature Correlation Matrix:\\n\", correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b32c478",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.80\n",
    "split_index = int(len(combined_df) * split_ratio)\n",
    "train_df = combined_df.iloc[:split_index]\n",
    "test_df = combined_df.iloc[split_index:]\n",
    "\n",
    "# Stock-specific scaling\n",
    "scalers_features = {}\n",
    "scalers_target = {}\n",
    "scaled_features_train = []\n",
    "scaled_targets_train = []\n",
    "scaled_features_test = []\n",
    "scaled_targets_test = []\n",
    "\n",
    "for stock in stock_order:\n",
    "    train_stock = train_df[train_df['Stock'] == stock][feature_columns]\n",
    "    test_stock = test_df[test_df['Stock'] == stock][feature_columns]\n",
    "    if train_stock.empty or test_stock.empty:\n",
    "        print(f\"Warning: Empty data for {stock}\")\n",
    "        continue\n",
    "    scaler_features = StandardScaler()\n",
    "    scaler_target = StandardScaler()\n",
    "    scalers_features[stock] = scaler_features\n",
    "    scalers_target[stock] = scaler_target\n",
    "    scaled_features_train.append(scaler_features.fit_transform(train_stock))\n",
    "    scaled_targets_train.append(scaler_target.fit_transform(train_df[train_df['Stock'] == stock][['Close']]))\n",
    "    scaled_features_test.append(scaler_features.transform(test_stock))\n",
    "    scaled_targets_test.append(scaler_target.transform(test_df[test_df['Stock'] == stock][['Close']]))\n",
    "\n",
    "scaled_features_train = np.concatenate(scaled_features_train)\n",
    "scaled_targets_train = np.concatenate(scaled_targets_train)\n",
    "scaled_features_test = np.concatenate(scaled_features_test)\n",
    "scaled_targets_test = np.concatenate(scaled_targets_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f512b42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences_per_stock(df, seq_length, feature_columns, target_column):\n",
    "    X, y = [], []\n",
    "    for stock in df['Stock'].unique():\n",
    "        stock_data = df[df['Stock'] == stock][feature_columns + [target_column]]\n",
    "        if stock_data.empty:\n",
    "            continue\n",
    "        features = stock_data[feature_columns].values\n",
    "        targets = stock_data[target_column].values\n",
    "        for i in range(seq_length, len(features)):\n",
    "            X.append(features[i-seq_length:i])\n",
    "            y.append(targets[i])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Create sequences\n",
    "X_train, y_train = create_sequences_per_stock(train_df, sequence_length, feature_columns, 'Close')\n",
    "X_test, y_test = create_sequences_per_stock(test_df, sequence_length, feature_columns, 'Close')\n",
    "print(f\"X_train shape: {X_train.shape} (samples, time_steps, features)\")\n",
    "print(f\"y_train shape: {y_train.shape} (samples, 1)\")\n",
    "print(f\"X_test shape: {X_test.shape} (samples, time_steps, features)\")\n",
    "print(f\"y_test shape: {y_test.shape} (samples, 1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50baa8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tf.keras.models\n",
    "layers = tf.keras.layers\n",
    "callbacks = tf.keras.callbacks\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.LSTM(units=100, return_sequences=True, input_shape=(sequence_length, n_features)),\n",
    "    layers.Dropout(0.3),\n",
    "    \n",
    "    layers.LSTM(units=100, return_sequences=True),\n",
    "    layers.Dropout(0.3),\n",
    "    \n",
    "    layers.LSTM(units=80, return_sequences=True),\n",
    "    layers.Dropout(0.2),\n",
    "    \n",
    "    layers.LSTM(units=80, return_sequences=False),\n",
    "    layers.Dropout(0.2),\n",
    "    \n",
    "    layers.Dense(units=50, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    \n",
    "    layers.Dense(units=1)  # CHANGED: Predict only 1 value\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "print(\"Model built successfully!\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c91f6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Phase1: Training model without early stopping\")\n",
    "start_time = time.time()\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(\"Training complete\")\n",
    "print(f\"Total training time: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16456bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss During Training')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8b57de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Phase2: Training model with early stopping\")\n",
    "start_time = time.time()\n",
    "\n",
    "early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "history2 = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(\"Training complete!\")\n",
    "print(f\"Total training time: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba68132",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(history2.history['loss'], label='Training Loss')\n",
    "plt.plot(history2.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss During Training')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed64dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('klse_bank_model.h5')\n",
    "print(\"Model saved\")\n",
    "\n",
    "joblib.dump(scaler_features, 'klse_bank_scaler_features.pkl')\n",
    "joblib.dump(scaler_target, 'klse_bank_scaler_target.pkl')\n",
    "print(\"Scaler saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
